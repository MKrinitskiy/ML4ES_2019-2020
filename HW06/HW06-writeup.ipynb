{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание №6\n",
    "\n",
    "Граф вычислений и обратное распространение ошибки для модели логистической регрессии\n",
    "<br />(частный случай: задача бинарной классификации)\n",
    "\n",
    "Срок сдачи: пятница, 24.04.2020\n",
    "<br />Вес задания: 1\n",
    "<br />Максимальный номинальный балл: 100\n",
    "<br />Максимальный итоговый балл: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "НАПОМНИМ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия - частный случай обобщенной линейной модели, в которой параметр $p(\\theta, x_i)$ распределения Бернулли, инетрпретируемый как вероятность объекта $x_i$ быть помеченным как класс \"1\", вычисляется следующим образом:\n",
    "\n",
    "$$\n",
    "p(\\theta, x_i) = \\frac{1}{1+\\exp({-\\theta \\cdot x_i})} = \\sigma(\\theta \\cdot x_i)\n",
    "$$\n",
    "\n",
    "В лекции было показано (покажите это в решении домашнего задания еще раз!), что градиент функции сигмоид $\\sigma(z)$ по аргументу вычисляется следующим образом:\n",
    "\n",
    "$$\n",
    "\\nabla_z \\sigma(z) = \\sigma(z)*(1-\\sigma(z))\n",
    "$$\n",
    "\n",
    "(следует помнить, что умножение здесь - поэлементное, [произведение Адамара](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5_%D0%90%D0%B4%D0%B0%D0%BC%D0%B0%D1%80%D0%B0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В соглашении, что классы кодируются как $y_i=0$ для \"отрицательных\" примеров и $y_i=1$ для \"положительных\", отрицательное правдоподобие выборки, совпадающее с функцией потерь на этой выборке $\\mathscr{T}=\\left\\{ y_i, x_i \\right\\}, i=1...N$ записывается следующим образом:\n",
    "\n",
    "$$\n",
    "\\mathscr{L}(\\mathscr{T}, \\theta) = -\\sum_{i=1}^{N}{\\left( y_i*\\ln{p_i}+(1-y_i)*\\ln{(1-p_i)} \\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задания:\n",
    "- Показать, что градиент функции сигмоид вычисляется через ее же значение так, как показано выше\n",
    "\n",
    "Рассмотреть задачу на плоскости (объекты $x_i$ описываются двумя действительными признаками).\n",
    "<br />\n",
    "Для такой задачи:\n",
    "- Нарисовать граф вычислений для $p(\\theta, x_i)$. Примечание: функцию $\\sigma$ можно записывать как унарную операцию, не раскрывая подробности вычислений внутри нее.\n",
    "- Нарисовать граф вычислений функции потерь $\\mathscr{L}(x_i, y_i, \\theta)$\n",
    "\n",
    "В решении ожидаются комментарии на предмет ожидаемого порядка вычислений на одном и втором графе, а также относительно того, какие входные данные необходимы для вычисления $p(\\theta, x_i)$ и $\\mathscr{L}(x_i, y_i, \\theta)$\n",
    "\n",
    "\n",
    "Обратитесь к задаче, решаемой в Лекции 11 (напомним, ноутбук, демонстрирующий применение логистической регрессии, доступен по [ссылке](https://github.com/MKrinitskiy/ML4ES_2019-2020/blob/master/Lect11/notebooks/Logistic%20regression%20demonstration.ipynb))\n",
    "- Сгенерируйте синтетические данные аналогично тому, как это сделано в демонстрационном коде к Лекции 11\n",
    "- В этом же ноутбуке доступен один из результатов оптимизации функции потерь - значения параметров модели $\\theta$, полученные в разделе \"Логистическая регрессия своими руками\". Используя эти значения, три примера сгенерированной выборки из различных областей на плоскости (\"положительный\" пример, \"отрицательный\" пример и пример, близкий к границе принятия решения), построенные графы вычисления $p(\\theta, x_i)$ и $\\mathscr{L}(x_i, y_i, \\theta)$ вычислите вручную $p(\\theta, x_i)$ и $\\mathscr{L}(x_i, y_i, \\theta)$. В решении ожидается демонстрация последовательности вычислений и комментарии на предмет того, сколько раз каждое вычисленное значение используется.\n",
    "- Используя технику вычисления градиентов на графе вычисления функции потерь, рассчитайте вручную градиенты функции потерь по параметрам $\\theta_0, \\theta_1, \\theta_2$ на всех трех примерах обучающей выборки. В решении ожидается демонстрация вычисления промежуточных результатов, а также комментарии на предмет того, сколько раз каждое вычисленное значение используется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
